{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\nintyfive\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\gensim\\utils.py:1212: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "# more common imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "# languange processing imports\n",
    "import nltk\n",
    "import string\n",
    "from gensim.corpora import Dictionary\n",
    "# preprocessing imports\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from pprint import pprint\n",
    "# model imports\n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "from gensim.models import CoherenceModel, Phrases, phrases\n",
    "from gensim.models.doc2vec import LabeledSentence\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from gensim.models.doc2vec import Doc2Vec\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read tables from mysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printable = set(string.printable)\n",
    "s = 'Ti\\u00ebsto'\n",
    "list(filter(lambda x: x in printable, s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read lyrics.csv\n",
    "data = pd.read_csv('lyrics.csv', names=['singer', 'song', 'lyrics'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    try:\n",
    "        return simple_preprocess(text)\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lyrics['singer'] = list(map(simple_preprocess, lyrics.singer))\n",
    "#lyrics['song'] = list(map(simple_preprocess, lyrics.singer))\n",
    "data['lyrics'] = list(map(preprocess, data.lyrics.values))\n",
    "data = data[~data['lyrics'].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# constrcut doc2vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_w2v_features(d2v_model, sentence):\n",
    "    #vector = d2v_model.docvecs[i]\n",
    "        \n",
    "    inferred_vector = d2v_model.infer_vector(sentence)\n",
    "    return inferred_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 6min 58s\n"
     ]
    }
   ],
   "source": [
    "from gensim.test.utils import get_tmpfile\n",
    "train_corpus = list(map(lambda i:TaggedDocument(data.loc[i].lyrics,['doc%d' % i]), data.index))\n",
    "\n",
    "model = Doc2Vec(min_count=1, window=10, vector_size=100, sample=1e-4, negative=5, workers=8, epochs=200)\n",
    "model.build_vocab(train_corpus)\n",
    "\n",
    "%time model.train(train_corpus, total_examples=model.corpus_count, epochs=model.epochs)\n",
    "\n",
    "#train_data3['w2v_features'] = list(map(lambda i:\n",
    "#                                      get_w2v_features(model, i),\n",
    "#                                      range(0, train_data3.shape[0])))\n",
    "fname = get_tmpfile(\"my_doc2vec_model\")\n",
    "\n",
    "model.save(fname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = get_tmpfile(\"my_doc2vec_model\")\n",
    "model = Doc2Vec.load(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 11850,\n",
       "         1: 17,\n",
       "         2: 2,\n",
       "         3: 3,\n",
       "         4: 4,\n",
       "         5: 2,\n",
       "         6: 5,\n",
       "         12: 2,\n",
       "         13: 1,\n",
       "         16: 2,\n",
       "         18: 2,\n",
       "         19: 2,\n",
       "         20: 2,\n",
       "         22: 3,\n",
       "         24: 1,\n",
       "         6938: 1})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranks = []\n",
    "for index, doc_id in enumerate(data.index):\n",
    "    inferred_vector = model.infer_vector(train_corpus[index].words)\n",
    "    sims = model.docvecs.most_similar([inferred_vector], topn=len(model.docvecs))\n",
    "    rank = [docid for docid, sim in sims].index('doc%d' % doc_id)\n",
    "    ranks.append(rank)\n",
    "    \n",
    "import collections\n",
    "collections.Counter(ranks) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6343    [shattered, shattered, love, and, hope, and, s...\n",
      "Name: lyrics, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(data[data['song'] == 'Shattered'].lyrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyric = 'Im a shattered  yeah  Pride and joy and greed and sex Thats what makes our town the best Pride and joy and dirty dreams'\n",
    "inferred_vector = model.infer_vector(lyric.split(' '))\n",
    "sims = model.docvecs.most_similar([inferred_vector], topn=len(model.docvecs))\n",
    "rank = [docid for docid, sim in sims].index('doc%d' % 6343)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 6872, 1: 3})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "with open('store_ranks.npy', 'wb') as writer:\n",
    "    pickle.dump(ranks, writer)\n",
    "    \n",
    "with open('store_ranks.npy', 'rb') as reader:\n",
    "    ranks3 = pickle.load(reader)\n",
    "collections.Counter(ranks3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read lyrics.csv\n",
    "data = pd.read_csv('lyrics.csv', names=['singer', 'song', 'lyrics'])\n",
    "data = data[~data['lyrics'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "count_vect = CountVectorizer().fit(data.lyrics.values)\n",
    "words_count = count_vect.transform(data.lyrics.values)\n",
    "\n",
    "tf_transformer = TfidfTransformer().fit(words_count)\n",
    "words_tfidf = tf_transformer.transform(words_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyric = 'who neglected you Owes a million dollars tax And your fathers still perfecting ways of making sealing wax'\n",
    "words_count = count_vect.transform([lyric])\n",
    "search_tfidf = tf_transformer.transform(words_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_result = pd.DataFrame(index=data.index, columns=['sim'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pr_index, pr in data.iterrows():\n",
    "    reviewed_iloc = data.index.get_loc(pr_index)\n",
    "    #print(reviewed_iloc)\n",
    "    if len(np.dot(search_tfidf[0], words_tfidf[reviewed_iloc].transpose()).tocoo().data) == 1: \n",
    "        similar_score = np.dot(search_tfidf[0], words_tfidf[reviewed_iloc].transpose()).tocoo().data[0] #if len(np.dot(words_tfidf[pr_iloc], words_tfidf[i].transpose()).tocoo().data) == 1]\n",
    "        similar_result.loc[pr_index, 'sim'] = similar_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10345</th>\n",
       "      <td>0.274625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6344</th>\n",
       "      <td>0.272511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6722</th>\n",
       "      <td>0.172306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4709</th>\n",
       "      <td>0.150619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8530</th>\n",
       "      <td>0.145479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2387</th>\n",
       "      <td>0.139094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8988</th>\n",
       "      <td>0.138011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2557</th>\n",
       "      <td>0.116804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6120</th>\n",
       "      <td>0.11586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9268</th>\n",
       "      <td>0.110611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6789</th>\n",
       "      <td>0.108872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1570</th>\n",
       "      <td>0.0988633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10606</th>\n",
       "      <td>0.0954065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4227</th>\n",
       "      <td>0.0917811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>667</th>\n",
       "      <td>0.0912372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11513</th>\n",
       "      <td>0.0908918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>0.0903492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11866</th>\n",
       "      <td>0.0873273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10325</th>\n",
       "      <td>0.0859872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1325</th>\n",
       "      <td>0.085987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2693</th>\n",
       "      <td>0.0848924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7222</th>\n",
       "      <td>0.0838936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9469</th>\n",
       "      <td>0.079637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5537</th>\n",
       "      <td>0.0793326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9671</th>\n",
       "      <td>0.0786451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11158</th>\n",
       "      <td>0.0782055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7377</th>\n",
       "      <td>0.0774519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10779</th>\n",
       "      <td>0.0762617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6792</th>\n",
       "      <td>0.0756326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9676</th>\n",
       "      <td>0.0737065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11318</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11319</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11324</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11327</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11337</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11340</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11346</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11368</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11377</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11436</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11438</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11445</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11449</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11450</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11455</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11462</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11482</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11568</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11600</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11721</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11727</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11738</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11753</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11764</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11846</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11872</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11885</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11886</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11890</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11904</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11899 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             sim\n",
       "10345   0.274625\n",
       "6344    0.272511\n",
       "6722    0.172306\n",
       "4709    0.150619\n",
       "8530    0.145479\n",
       "2387    0.139094\n",
       "8988    0.138011\n",
       "2557    0.116804\n",
       "6120     0.11586\n",
       "9268    0.110611\n",
       "6789    0.108872\n",
       "1570   0.0988633\n",
       "10606  0.0954065\n",
       "4227   0.0917811\n",
       "667    0.0912372\n",
       "11513  0.0908918\n",
       "477    0.0903492\n",
       "11866  0.0873273\n",
       "10325  0.0859872\n",
       "1325    0.085987\n",
       "2693   0.0848924\n",
       "7222   0.0838936\n",
       "9469    0.079637\n",
       "5537   0.0793326\n",
       "9671   0.0786451\n",
       "11158  0.0782055\n",
       "7377   0.0774519\n",
       "10779  0.0762617\n",
       "6792   0.0756326\n",
       "9676   0.0737065\n",
       "...          ...\n",
       "11318        NaN\n",
       "11319        NaN\n",
       "11324        NaN\n",
       "11327        NaN\n",
       "11337        NaN\n",
       "11340        NaN\n",
       "11346        NaN\n",
       "11368        NaN\n",
       "11377        NaN\n",
       "11436        NaN\n",
       "11438        NaN\n",
       "11445        NaN\n",
       "11449        NaN\n",
       "11450        NaN\n",
       "11455        NaN\n",
       "11462        NaN\n",
       "11482        NaN\n",
       "11568        NaN\n",
       "11600        NaN\n",
       "11721        NaN\n",
       "11727        NaN\n",
       "11738        NaN\n",
       "11753        NaN\n",
       "11764        NaN\n",
       "11846        NaN\n",
       "11872        NaN\n",
       "11885        NaN\n",
       "11886        NaN\n",
       "11890        NaN\n",
       "11904        NaN\n",
       "\n",
       "[11899 rows x 1 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar_result.sort_values(by=['sim'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# trying fuzzy string comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\nintyfive\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\fuzzywuzzy\\fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "choices = [\"Atlanta Falcons\", \"New York Jets\", \"New York Giants\", \"Dallas Cowboys\"]\n",
    "process.extract(\"new york jets\", choices, limit=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "singer                                   The Rolling Stones\n",
       "song                                              Shattered\n",
       "lyrics    Shattered  shattered Love and hope and sex and...\n",
       "Name: 6343, dtype: object"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[6343]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fuzz.ratio(\"Im a shattered  yeah  Pride and joy and greed and sex Thats what makes our town the best Pride and joy and dirty dreams\", 'Shattered  shattered Love and hope and sex and dreams Are still surviving on the street Look at me  Im in tatters Im a shattered Shattered  Friends are so alarming And my lovers never charming Lifes just a cocktail party on the street Big Apple People dressed in plastic bags Directing traffic Some kind of fashion Shattered  Laughter  joy  and loneliness and sex and sex and sex and sex Look at me  Im in tatters Im a shattered Shattered  All this chitter-chatter  chitter-chatter  chitter-chatter about Shmatta  shmatta  shmatta  I cant give it away on 7th Avenue This towns been wearing tatters shattered  shattered Work and work for love and sex Aint you hungry for success  success  success  success Does it matter? Shattered Does it matter? Im shattered Shattered  Ahhh  look at me  Im a shattered Im a shattered Look at me  Im a shattered  yeah  Pride and joy and greed and sex Thats what makes our town the best Pride and joy and dirty dreams and still surviving on the street And look at me  Im in tatters  yeah Ive been battered  what does it matter Does it matter  uh-huh Does it matter  uh-huh  Im a shattered Dont you know the crime rate is going up  up  up  up  up To live in this town you must be tough  tough  tough  tough  tough! You got rats on the west side Bed bugs uptown What a mess this towns in tatters Ive been shattered My brains been battered  splattered all over Manhattan  Uh-huh  this towns full of money grabbers Go ahead  bite the Big Apple  dont mind the maggots  huh Shadoobie  my brains been battered My friends they come around they Flatter  flatter  flatter  flatter  flatter  flatter  flatter Pile it up  pile it high on the platter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex\n",
    "result = regex.match('(Im a yeah  Pride and joy and greed and sex Thats what makes our town the best Pride and joy and dirty dreams){e<=1}', 'Shattered  shattered Love and hope and sex and dreams Are still surviving on the street Look at me  Im in tatters Im a shattered Shattered  Friends are so alarming And my lovers never charming Lifes just a cocktail party on the street Big Apple People dressed in plastic bags Directing traffic Some kind of fashion Shattered  Laughter  joy  and loneliness and sex and sex and sex and sex Look at me  Im in tatters Im a shattered Shattered  All this chitter-chatter  chitter-chatter  chitter-chatter about Shmatta  shmatta  shmatta  I cant give it away on 7th Avenue This towns been wearing tatters shattered  shattered Work and work for love and sex Aint you hungry for success  success  success  success Does it matter? Shattered Does it matter? Im shattered Shattered  Ahhh  look at me  Im a shattered Im a shattered Look at me  Im a shattered  yeah  Pride and joy and greed and sex Thats what makes our town the best Pride and joy and dirty dreams and still surviving on the street And look at me  Im in tatters  yeah Ive been battered  what does it matter Does it matter  uh-huh Does it matter  uh-huh  Im a shattered Dont you know the crime rate is going up  up  up  up  up To live in this town you must be tough  tough  tough  tough  tough! You got rats on the west side Bed bugs uptown What a mess this towns in tatters Ive been shattered My brains been battered  splattered all over Manhattan  Uh-huh  this towns full of money grabbers Go ahead  bite the Big Apple  dont mind the maggots  huh Shadoobie  my brains been battered My friends they come around they Flatter  flatter  flatter  flatter  flatter  flatter  flatter Pile it up  pile it high on the platter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "choices = data.lyrics.values\n",
    "%time process.extract(\"Im a shattered  yeah  Pride and joy and greed and sex Thats what makes our town the best Pride and joy and dirty dreams\", choices, limit = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({False: 8602})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(reviewers_semantic_sim['rchande'].isnull())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
